{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4032462b",
   "metadata": {},
   "source": [
    "# Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2345991a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing all the modules and functions related to constructing MLP network models\n",
    "\n",
    "from network.net import Net                   # Net class, base class for constructing MLP networks\n",
    "from network.layer import Linear              # Linear class, child class of parent class Layer \n",
    "from network.loss import CrossEntropyLoss     # CrossEntropyLoss class, child class of parent class Loss\n",
    "from network.activ import ReLU, LeakyReLU     # ReLU, LeakyReLU classes, child classes of parent class Activation\n",
    "from network.optim import SGD, Adam           # SGD, Adam classes, child classes of parent class Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5bc9454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing all the modules and functions related to data processing including loaders for the assignment data\n",
    "\n",
    "# Process module contains functions relating to data processing:\n",
    "from network.loader.process import (\n",
    "    train_test_split,        # Function to split data with chosen ratio, data can be shuffled\n",
    "    normalize,               # Normalizes data to have mean of zero and unit variance\n",
    "    standardize,             # Normalizes data to be between range 0-1, i.e. standardizes data\n",
    "    one_hot,                 # One hot encoding: 100% prob of 2 is [0, 0, 1] with 3 classes\n",
    "    pca                      # Reduces data to chosen K principal components\n",
    ") \n",
    "\n",
    "# Data module for loading the assignment data\n",
    "from network.dataset.source import (\n",
    "    get_data_from_file,   # Loads assignment data from file (must be within main directory)\n",
    "    get_data_from_url     # Loads assignment data from public GitHub repo that stores data\n",
    ")\n",
    "\n",
    "# Data loader module for automating processing of and loading of assignment data based on parameter selections\n",
    "from network.loader.data_loader import load_train_val_test  # Parameter selections decide method of processing\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as pl\n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "\n",
    "# setting random seed\n",
    "np.random.seed(90)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5486355",
   "metadata": {},
   "source": [
    "### Plotting Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f51955f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(stats):\n",
    "    ep, tl, ta, vl, va = stats\n",
    "    pl.figure(figsize = (10, 7))\n",
    "\n",
    "    fig, ((ax1, ax2), (ax3, ax4)) = pl.subplots(2, 2)\n",
    "    fig.suptitle(f'Training Results, best model found @ Epoch {ep}')\n",
    "\n",
    "    ax1.plot(tl)\n",
    "    ax1.set_title('Training Loss')\n",
    "\n",
    "    ax2.plot(vl, 'tab:orange')\n",
    "    ax2.set_title('Validation Loss')\n",
    "\n",
    "    ax3.plot(ta, 'tab:green')\n",
    "    ax3.set_title('Training Accuracy')\n",
    "\n",
    "    ax4.plot(va, 'tab:red')\n",
    "    ax4.set_title('Validation Accuracy')\n",
    "    \n",
    "    for ax in fig.get_axes():\n",
    "        ax.label_outer()\n",
    "\n",
    "    pl.show()\n",
    "    \n",
    "def confusion_matrix(pred, label):\n",
    "    x, y = len(np.unique(pred)), len(np.unique(label))\n",
    "    matrix = np.zeros((x, y))\n",
    "    for i in range(len(pred)):\n",
    "        m, n = pred[i], label[i]\n",
    "        matrix[m, n] += 1\n",
    "    return matrix       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afda8d00",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab408682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note as we are loading data from URL it will take longer than from file.\n",
    "train_set, valid_set, test_set = load_train_val_test(\n",
    "    source = \"url\", \n",
    "    method = \"standardize\", \n",
    "    pca_N = 0, \n",
    "    n_categories = 10, \n",
    "    ratio = 0.2, \n",
    "    shuffle = True\n",
    ")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0cb446",
   "metadata": {},
   "source": [
    "# Model Initialization\n",
    "\n",
    "##### Changed learning_rate = 0.01 (from 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d736ee04",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = Net(\n",
    "    optimizer = Adam(\n",
    "        learning_rate = 0.01  # Default value\n",
    "    ),\n",
    "    criterion = CrossEntropyLoss(),\n",
    "    batch_norm = True,\n",
    "    L2_reg_term = 0.001\n",
    ")\n",
    "\n",
    "mlp.add(Linear(128, 1024, dropout=0.4))\n",
    "mlp.add(ReLU())\n",
    "mlp.add(Linear(1024, 512, dropout=0.2))\n",
    "mlp.add(ReLU())\n",
    "mlp.add(Linear(512, 64, dropout=0.2))\n",
    "mlp.add(ReLU())\n",
    "mlp.add(Linear(64, 16, dropout=0.2))\n",
    "mlp.add(ReLU())\n",
    "mlp.add(Linear(16, 10))  \n",
    "\n",
    "\n",
    "mlp.set_name(\"Best_model\")\n",
    "mlp.save_model()  # for reload\n",
    "\n",
    "print(f\"{mlp.model_name} is initialized and ready to be trained.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0424a7e",
   "metadata": {},
   "source": [
    "## Train and Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8c071e",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = mlp.train_convergence(\n",
    "    train_set = train_set,\n",
    "    valid_set = valid_set,\n",
    "    batch_size = 500,\n",
    "    planned_epochs = 100,\n",
    "    last_check = 10,\n",
    "    threshold = 1e-25,\n",
    "    report_interval = 5\n",
    ")\n",
    "\n",
    "{\"tags\": [\"hide-output\"]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3ed657",
   "metadata": {},
   "source": [
    "### Plotting Epoch-wise Loss & Accuracy Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f882ee7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(stats)  # plot curves"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c9d1c5",
   "metadata": {},
   "source": [
    "### Checking Accuracy of Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae1f44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading best model found:\n",
    "\n",
    "best_model = Net.load_model(\"model/\" + mlp.model_name)\n",
    "best_model.test_network(train_set, \"train data\")\n",
    "best_model.test_network(valid_set, \"valid data\")\n",
    "best_model.test_network(test_set, \"test data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77fb7160",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf6bab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix of training data\n",
    "\n",
    "pred = best_model.predict(train_set[0], train_set[1].shape[1])\n",
    "pred_train_labels = np.argmax(pred, axis=1)\n",
    "\n",
    "matrix = confusion_matrix(pred_train_labels, np.argmax(train_set[1], axis=1))\n",
    "matrix = pd.DataFrame(matrix, index = np.arange(10), columns = np.arange(10))\n",
    "\n",
    "pl.figure(figsize = (10,7))\n",
    "sns.heatmap(matrix, annot=True)\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9deeb0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix of test data\n",
    "\n",
    "pred = best_model.predict(test_set[0], test_set[1].shape[1])\n",
    "pred_test_labels = np.argmax(pred, axis=1)\n",
    "\n",
    "matrix = confusion_matrix(pred_test_labels, np.argmax(test_set[1], axis=1))\n",
    "matrix_df = pd.DataFrame(matrix, index = np.arange(10), columns = np.arange(10))\n",
    "\n",
    "pl.figure(figsize = (10,7))\n",
    "sns.heatmap(matrix, annot=True)\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e5c84a",
   "metadata": {},
   "source": [
    "### F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5a01ac7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Only used in evaluation\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m f1_score\n\u001b[0;32m      4\u001b[0m f1_class \u001b[38;5;241m=\u001b[39m f1_score(test_set[\u001b[38;5;241m1\u001b[39m], pred_test_labels, average \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweighted\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF1 Score:\u001b[39m\u001b[38;5;124m\"\u001b[39m, np\u001b[38;5;241m.\u001b[39mround(f1_class, \u001b[38;5;241m5\u001b[39m))\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "# Only used in evaluation\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1_class = f1_score(test_set[1], pred_test_labels, average = 'weighted')\n",
    "    \n",
    "print(\"F1 Score:\", np.round(f1_class, 5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
